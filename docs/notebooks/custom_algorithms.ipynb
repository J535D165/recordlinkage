{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom algorithms\n",
    "\n",
    "The Python Record Linkage Toolkit contains several built-in algorithms for making record pairs and comparing record pairs. Sometimes, these built-in algorithms do not fit your needs. With the Python Record Linkage Toolkit, it is easy to use other algorithms. This section describes how to implement custom algorithms for the making and comparing record pairs. When you think your algorithm might help others, consider sharing it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hide_input": false,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%precision 5\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas\n",
    "pandas.set_option('precision',5)\n",
    "pandas.options.display.max_rows = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For run the examples below, import *pandas*, *recordlinkage* and the two datasets belonging to sample dataset [FEBRL4](../reference.html#recordlinkage.datasets.load_febrl4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "import recordlinkage as rl\n",
    "from recordlinkage.datasets import load_febrl4\n",
    "\n",
    "df_a, df_b = load_febrl4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom index algorithms\n",
    "The Python Record Linkage Toolkit contains multiple algorithms to pair records (index algorithms) such as [full indexing](../reference.html#recordlinkage.indexing.FullIndex), [blocking](../reference.html#recordlinkage.indexing.BlockIndex) and [sorted neighbourhood indexing](../reference.html#recordlinkage.indexing.SortedNeighbourhoodIndex). This section explains how to make and implement a custom algorithm to make record pairs. \n",
    "\n",
    "To create a custom algorithm, you have to make a subclass of the ``recordlinkage.base.BaseIndexator``. In your subclass, you overwrite the ``_link_index`` method. This method accepts two pandas DataFrames as arguments. Based on these DataFrames, your method must create pairs and return them as a ``pandas.MultiIndex`` in which the MultiIndex names are the index names of DataFrame A and DataFrame B respectively. \n",
    "\n",
    "The algorithm for linking data frames can be used for finding duplicates as well. In this situation, DataFrame B is a copy of DataFrame A. The ``Pairs`` class removes pairs like ``(record_i, record_i)`` and one of the following ``(record_i, record_j) (record_j, record_i)`` under the hood. As result of this, only unique combinations are returned. If you do have a specific algorithm for finding duplicates, then you can overwrite the ``_dedup_index`` method. This method accepts only one argument (DataFrame A) and the internal base class does not look for combinations like explained above. \n",
    "\n",
    "Let's make an algorithm that pairs records of which the given name in both records starts with the letter 'W'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recordlinkage.base import BaseIndexator\n",
    "\n",
    "class FirstLetterWIndex(BaseIndexator):\n",
    "    \"\"\"Custom class for indexing\"\"\"\n",
    "    \n",
    "    def _link_index(self, df_a, df_b):\n",
    "        \"\"\"Make pairs of all records where the given name start with the letter 'W'.\"\"\"\n",
    "\n",
    "        # Select records with names starting with a w.\n",
    "        name_a_startswith_w = df_a[df_a['given_name'].str.startswith('w') == True]\n",
    "        name_b_startswith_w = df_b[df_b['given_name'].str.startswith('w') == True]\n",
    "\n",
    "        # Make a product of the two numpy arrays\n",
    "        return pandas.MultiIndex.from_product(\n",
    "            [name_a_startswith_w.index.values, name_b_startswith_w.index.values],\n",
    "            names=[df_a.index.name, df_b.index.name]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns a MultiIndex\n",
      "Number of candidate record pairs starting with the letter w: 6072\n"
     ]
    }
   ],
   "source": [
    "indexer = FirstLetterWIndex()\n",
    "candidate_pairs = indexer.index(df_a, df_b)\n",
    "\n",
    "print ('Returns a', type(candidate_pairs).__name__)\n",
    "print ('Number of candidate record pairs starting with the letter w:', len(candidate_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom index class below does not restrict the first letter to 'w', but the first letter is an argument (named ``letter``). This letter can is initialized during the setup of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FirstLetterIndex(BaseIndexator):\n",
    "    \"\"\"Custom class for indexing\"\"\"\n",
    "    \n",
    "    def __init__(self, letter):\n",
    "        super(FirstLetterIndex, self).__init__()\n",
    "\n",
    "        # the letter to save\n",
    "        self.letter = letter\n",
    "        \n",
    "    def _link_index(self, df_a, df_b):\n",
    "        \"\"\"Make record pairs that agree on the first letter of the given name.\"\"\"\n",
    "\n",
    "        # Select records with names starting with a 'letter'.\n",
    "        a_startswith_w = df_a[df_a['given_name'].str.startswith(self.letter) == True]\n",
    "        b_startswith_w = df_b[df_b['given_name'].str.startswith(self.letter) == True]\n",
    "\n",
    "        # Make a product of the two numpy arrays\n",
    "        return pandas.MultiIndex.from_product(\n",
    "            [a_startswith_w.index.values, b_startswith_w.index.values],\n",
    "            names=[df_a.index.name, df_b.index.name]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of record pairs (letter w): 6072\n"
     ]
    }
   ],
   "source": [
    "indexer = FirstLetterIndex('w')\n",
    "candidate_pairs = indexer.index(df_a, df_b)\n",
    "\n",
    "print ('Number of record pairs (letter w):', len(candidate_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of record pairs (letter w): 6072\n",
      "Number of record pairs (letter x): 132\n",
      "Number of record pairs (letter a): 172431\n"
     ]
    }
   ],
   "source": [
    "for letter in 'wxa':\n",
    "    \n",
    "    indexer = FirstLetterIndex(letter)\n",
    "    candidate_pairs = indexer.index(df_a, df_b)\n",
    "\n",
    "    print ('Number of record pairs (letter %s):' % letter, len(candidate_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom compare algorithms\n",
    "\n",
    "The Python Record Linkage Toolkit holds algorithms to compare strings, numeric values and dates. These functions may not be sufficient for your record linkage. The internal framework of the toolkit makes it easy to implement custom algorithms to compare records. \n",
    "\n",
    "A custom algorithm is a function that accepts two arguments, one ``pandas.Series`` with information on the variable in the first file and one ``pandas.Series`` with information on the variable in the second file. The function returns a ``pandas.Series``, ``numpy.array`` or list with the similarity/comparison values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_zipcodes(s1, s2):\n",
    "    \"\"\"\n",
    "    If the zipcodes in both records are identical, the similarity \n",
    "    is 0. If the first two values agree and the last two don't, then \n",
    "    the similarity is 0.5. Otherwise, the similarity is 0.\n",
    "    \"\"\"\n",
    "\n",
    "    # check if the zipcode are identical (return 1 or 0)\n",
    "    sim = (s1 == s2).astype(float)\n",
    "\n",
    "    # check the first 2 numbers of the distinct comparisons\n",
    "    sim[(sim == 0) & (s1.str[0:2] == s2.str[0:2])] = 0.5\n",
    "    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    71229\n",
       "0.5     3166\n",
       "1.0     2854\n",
       "Name: sim_postcode, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make an index of record pairs\n",
    "pcl = rl.BlockIndex('given_name')\n",
    "candidate_pairs = pcl.index(df_a, df_b)\n",
    "\n",
    "\n",
    "crl = rl.Compare(candidate_pairs, df_a, df_b)\n",
    "\n",
    "# default algorithm\n",
    "crl.string('surname', 'surname', method='jarowinkler', name='sim_surname')\n",
    "\n",
    "# custom zipcodes algorithm\n",
    "# crl.compare(callable_algorithm, 'label_A', 'label_B', name='sim_name')\n",
    "crl.compare(compare_zipcodes, 'postcode', 'postcode', name='sim_postcode')\n",
    "\n",
    "crl.vectors['sim_postcode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, one can pass the labels of the columns as arguments. The first argument is a column label, or a list of column labels, found in the first DataFrame (``postcode`` in this example). The second argument is a column label, or a list of column labels, found in the second DataFrame (also ``postcode`` in this example). The ``recordlinkage.Compare`` class selects the columns with the given labels before passing them to the custom algorithm/function. The ``compare`` method in the ``recordlinkage.Compare`` class passes additional (keyword) arguments to the custom function. \n",
    "\n",
    "**Warning:** Do not change the order of the pairs in the MultiIndex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicolumn comparisons\n",
    "The Python Record Linkage Toolkit supports the comparison of more than two columns. This is especially useful in situations with multi-dimensional data (for example geographical coordinates) and situations where fields can be swapped. \n",
    "\n",
    "The FEBRL4 dataset has two columns filled with address information (``address_1`` and ``address_2``). In a naive approach, one compares ``address_1`` of file A with ``address_1`` of file B and ``address_2`` of file A with ``address_2`` of file B. If the values for ``address_1`` and ``address_2`` are swapped during the record generating process, the naive approach considers the addresses to be distinct. In a more advanced approach, ``address_1`` of file A is compared with ``address_1`` and ``address_2`` of file B. Variable ``address_2`` of file A is compared with ``address_1`` and ``address_2`` of file B. This is done with the single function given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_addresses(s1_1, s1_2, s2_1, s2_2):\n",
    "    \"\"\"\n",
    "    Compare addresses. Compare address_1 of file A with \n",
    "    address_1 and address_2 of file B. The same for address_2\n",
    "    of dataset 1. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return ((s1_1 == s2_1) | (s1_2 == s2_2) | (s1_1 == s2_2) | (s1_2 == s2_1)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sim_address_1    0.02488\n",
       "sim_address_2    0.02025\n",
       "sim_address      0.03566\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crl = rl.Compare(candidate_pairs, df_a, df_b)\n",
    "\n",
    "# naive\n",
    "crl.exact('address_1', 'address_1', name='sim_address_1')\n",
    "crl.exact('address_2', 'address_2', name='sim_address_2')\n",
    "\n",
    "# better\n",
    "crl.compare(compare_addresses, ['address_1', 'address_2'], ['address_1', 'address_2'], name='sim_address')\n",
    "\n",
    "crl.vectors.mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
